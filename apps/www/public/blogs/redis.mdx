---
title: Test Redis with Docker
seoTitle: Automated Containerized Approach For Testing Redis Connections In CI pipelines
summary: Automated containerized approach to test Redis in CI
isReleased: false
isSequel: false
firstModDate: 2020-04-12T09:15:00-0400
lastModDate: 2020-04-12T09:15:00-0400
minutesToRead: 5
tags:
  - 'redis'
  - 'docker'
  - 'testing'
---
  

<H2>Problem</H2>
<C>
  So, you're using <L href="https://redis.com/">Redis</L> to keep your API's rate in check, you're probably using cloud instances for prod and you're trying to
  test your app logic, assuming you resisted your natural inclination to <L href="/blog/mock-async-python">mock</L> these connections and call it a day, so how do you test them ? 
</C>
<H2>Solution</H2>
<C>
It's obvious right, have a mechanism that switches between 
testing instances and real instances, of course, this is not
 hard to implement, the thing is: how do you automate these tests and have them work, even in CI?
<S/>
Well the short answer is a shell a script that spins **Docker**
 containers up and tears them down later, and cleanup after.
</C>
<H2>
Demo
</H2>
<C>
I'll be using Python for this demo with <L href="https://fastapi.tiangolo.com/">FastAPI</L> as a framework, but it doesn't matter, the core concept remains the same regardless of the stack being used.

<S />
  Pre-requisites: 
  - \-  Python 
  - \-  Docker & Compose 

  <S2 />
  These are the basic rate limited endpoints
</C>


<Code
  code={`RATE_LIMITED_PATHS = [
    "/limited-1",
    "/limited-2",
    "/limited-3",
    "/limited-4",
    "/limited-5",
]
`}
  language="python"
  showLineNumbers={false}
/>
<C>Where if you curl any of these endpoints once every 20 secs you should get </C>
<Code
  code={`➜  curl http://localhost:8000/limited-2
{"detail":"you'll see me once every 20 seconds"}  
`}
  language="bash"
  showLineNumbers={false}
/>
<C>Whereas if you curl any of these endpoints twice per 20s you should get</C>
<Code
  code={`➜  curl http://localhost:8000/limited-2
{"detail":"Too Many Requests"}  
`}
  language="bash"
  showLineNumbers={false}
/>

<S3 />
<C>
  For the rate limiting logic, I'll use <L href="https://github.com/long2ice/fastapi-limiter/">``fastapi_limiter``</L>. Though you can
  roll out your own.
</C>
<C>Here's a state of the art, robust, elegant and 120% prod ready service</C>
<Code
  code={`from __future__ import annotations

import redis.asyncio as raio  # type: ignore # missing stubs

from typing import AsyncGenerator
from os import getenv
from dataclasses import dataclass
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI, Request, Response, Depends
from fastapi.responses import JSONResponse
from fastapi_limiter import FastAPILimiter  # type: ignore # missing stubs
from fastapi_limiter.depends import RateLimiter  # type: ignore # missing stubs
from uvicorn import run


load_dotenv()

RATE_LIMITED_PATHS = [
    "/limited-1",
    "/limited-2",
    "/limited-3",
    "/limited-4",
    "/limited-5",
]


@dataclass
class RedisData:
    PORT = getenv("REDIS_PORT")
    USERNAME = getenv("REDIS_USERNAME")
    PASSWORD = getenv("REDIS_PASSWORD")

# You probably have some logic to switch between prod & dev environments.
async def local_redis_connection() -> raio.Redis:
    return await raio.from_url(
        url=f"redis://{RedisData.USERNAME}:{RedisData.PASSWORD}@localhost:{RedisData.PORT}",
        encoding="utf-8",
        decode_responses=True,
    )


@asynccontextmanager
async def lifespan(_app: FastAPI) -> AsyncGenerator[None, None]:
    await FastAPILimiter.init(await local_redis_connection()) # run when: app starts
    yield
    await FastAPILimiter.close()                        # run when: app shuts down


async def limiter_dependency(req: Request, res: Response) -> None:
    if req.url.path in RATE_LIMITED_PATHS:
        await RateLimiter(times=1, seconds=20).__call__(req, res)


api = FastAPI(
    dependencies=[Depends(limiter_dependency)],
    lifespan=lifespan,
)


for path in RATE_LIMITED_PATHS:
    @api.get(path, tags=["rate_limited"])
    def rate_limited() -> JSONResponse:
        return JSONResponse({"detail":"you'll see me once a minute"})


if __name__ == "__main__":
    run(api, host="0.0.0.0", port=8000)
`}
  language="python"
  showLineNumbers={false}
/>
<C>The current project structure:</C>

<Code
  code={`.
├── api.py
├── compose.yaml
├── .env
├── poetry.lock
├── pyproject.toml
├── redis.conf
├── redis.dockerfile
├── test # shell script 
└── test.py
`}
  language="bash"
  showLineNumbers={false}
/>
<C>Here's the **`redis.conf`** file</C>
<Code
  code={`bind 0.0.0.0
requirepass be1bd008f6f7d353bdf4d941c3ee6ed2
port 40185
maxmemory 100MB
maxmemory-policy volatile-lru
protected-mode no
`}
  language="bash"
  showLineNumbers={false}
/>

<C>
  This is the most basic config you can use for testing purposes. you can read
  more about all the config options
  <L href="https://redis.io/docs/management/config-file">here</L>
  <S3 />
  To actually run it you'll need a **Dockerfile**
</C>

<Code
  code={`FROM redis:6.2.7

WORKDIR .
COPY redis.conf redis.conf

# disable THP support

RUN echo "echo never > /sys/kernel/mm/transparent_hugepage/enabled" > /etc/rc.local \

&& chmod +x /etc/rc.local

# resolve latency memory issues

RUN echo "vm.overcommit_memory = 1" >> /etc/sysctl.conf \
 && cat /etc/sysctl.conf

CMD ["redis-server", "redis.conf"]
`}
language="docker"
showLineNumbers={false}
/>

<C>You can run this directly with Docker but I prefer to use **``docker-compose``** instead</C>

<Code
  code={`version: "3"
services:
  redis_limiter:
    build:
      context: .
      dockerfile: redis.dockerfile
    container_name: redis_limiter_test
    restart: always
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 100M
    volumes: # optional 
      - redis_limiter_volume_data:/volumes/limiter
    ports:
      - 40185:40185

volumes: # optional 
  redis_limiter_volume_data:
`}
  language="yaml"
  showLineNumbers={false}
/>
<C>If you run compose now with</C>
<Code
  code={`docker-compose up 
`}
  language="bash"
  showLineNumbers={false}
/>

<C>
  You'll have Redis running, but how do you coordinate with the app you're
  trying to run? To ensure it only starts when Redis is up and running, one way
  is to curl the Redis server. If the curl operation is successful, proceed to
  run the app and conduct tests, though attempting to curl Redis will likely
  result in receiving
</C>
<Code
  code={`(venv) ➜  redis-limiter git:(main) curl http://localhost:40185 --verbose 
*   Trying [::1]:40185...
* Connected to localhost (::1) port 40185
> GET / HTTP/1.1
> Host: localhost:40185
> User-Agent: curl/7.81.0
> Accept: */*
> 
* Received HTTP/0.9 when not allowed
* Closing connection
curl: (1) Received HTTP/0.9 when not allowed 
`}
  language="bash"
  showLineNumbers={false}
/>
<C>
  To work around this, you could either run your API with **``compose``** as well.
  However, for testing purposes, this might be totally unnecessary. Another
  workaround is to have a service act as a trigger that you can curl. This
  service depends on Redis, ensuring that it only runs if Redis is functioning
  correctly. An example of such a service could be an **NGINX** server (~48MB image), that returns
   a non null response upon curling. The modified
  **`compose.yaml`** file is updated as follows:
</C>
<Code
  code={`version: "3"
services:
  redis_limiter:
    build:
      context: .
      dockerfile: redis.dockerfile
    container_name: redis_limiter_test
    restart: always
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 250M
    volumes: # optional 
      - redis_limiter_volume_data:/volumes/limiter
    ports:
      - 40185:40185

  nginx_trigger:
    image: nginx:latest
    container_name: nginx_trigger_container
    restart: always
    depends_on:
      - redis_limiter
    ports:
      - 8001:80


volumes: # optional 
  redis_limiter_volume_data:
`}
  language="yaml"
  showLineNumbers={false}
/>

<C>Now if you run compose again:</C>
<Code
  code={`➜  redis-limiter git:(main) docker-compose up  
[+] Building 0.0s (0/0)                                                                                                                 docker:default
[+] Running 3/3
 ✔ Network redis-limiter_default      Created                                                                                                     0.1s 
 ✔ Container redis_limiter_test       Created                                                                                                     0.1s 
 ✔ Container nginx_trigger_container  Created     
`}
  language="bash"
  showLineNumbers={false}
/>
<C>Use this **``test``** script to test your service </C>
<Code
  code={`#!/usr/bin/bash
docker-compose up -d
until curl http://localhost:8001 &>/dev/null; do
  sleep 1
done
python -m api & 
server_pid=$!
## 
pytest # or any testing tool or scripts to use 
##
kill $server_pid 
docker-compose down 
`}
  language="bash"
  showLineNumbers={false}
/>
<C>
 This script orchestrates the **docker-compose** configs, runs it in the background, 
  waits for the **NGINX** trigger
  to be accessible, runs the **FastAPI** app, executes tests, shuts down the
  server, and tears down the **Docker** containers.
</C>
<S3 />
<C>You can implement your own testing logic, using any test runner.</C>
<S/>
<C>Now since I'm using **FastAPI**  I will omit the server running step from the test script
, as **FastAPI** provides a **``TestClient``** class  you can use to test your app logic 
without having to actually run the server. Also if you're using <L href='https://www;pytest.org'>**``Pytest``**</L> you can skip/ignore tests if a 
condition is not met, in this case, if no containers are spinning, skip. The idea might be like</C>
<Code
  code={`import pytest
import requests

from _pytest.mark import MarkDecorator
from fastapi.testclient import TestClient
from api import api

client = TestClient(app=api)

might_skip: MarkDecorator = pytest.mark.skipif(
    not requests.get("http://localhost:8001").ok, reason="Containers not spinning"
)


@might_skip
async def do_some_tests(): ...  # use the test client
`}
  language="python"
  showLineNumbers={false}
/>
<C>If you use **Go** for example an abstract setup might be like</C>
<Code
  code={`.
├── api
│   └── main.go
├── docker-compose.yaml
├── .env
├── go.mod
├── go.sum
├── redis.conf
├── redis.dockerfile
├── scripts
│   └── test.sh
└── test
    └── test.go
`}
  language="bash"
  showLineNumbers={false}
/>

<C>But the idea remains the same, scale redis container(s) before tests and scale down and clean up after, the only part changing in the script 
is the test runner, instead of Python's **``pytest``** it'll be **`go test`**, if you use Rust then it's  **`cargo test`** and so on.</C>